---
title: "SD_Disscusion 2"
author: "Steve Dunn"
date: "June 22, 2016"
output: html_document
---

Prof. Andy Catlin
IS 643 - Special Topics: Recommender Systems
Department of Data Analytics, City University of New York


#Discussion 2


The recsys talk that I choose was on Predicting Online Performance of News Recommender Systems through Richer Evaluation Metrics
By Andrii Maksai, Florent Garcin and Boi Faltings
https://www.youtube.com/watch?v=m-BSIVT8Wrg&index=11&list=PLaZufLfJumb_EWKKxZatnLNinoVQ94uXe 


###Briefly summarize what you found to be the most important ideas from the talk;

For online news site that advertise to users that come to their site for a particular news story but then leave after reading that one article the need is there to keep the user on the site longer to maximize the revenue potential of the site so a personalized recommender system would need to be developed /trained . How to achieve this personalization via off line testing was discussed and I found the approach intriguing because of the relative accuracy that can be achieved depending on the mix of the varying metrics applied. This is important from a business perspective because it directly affects potential revenues via Ads. Traditional news feed recommend articles based on previous visit to the site, related articles by topic or top news of the day. Some random data collection solution that was explored by Li et al (2011) for yahoo is a possible solution for a personalized results via evaluation metrics, however this only worked for a small number of recommendations, 20 items in the case of yahoo. This system does not work for the scope of the research and so they implemented offline evaluation metrics that evaluate result for  larger datasets  and then  connect to an online test site and use their regression model to see  how accurate the off line metrics predict the online performance. They grouped 17 metrics into Accuracy, Diversity, Coverage, Serendipity and , Novelty.



![Measure of the offline performance metrics of different algorithms on off line data and then apply a regression model to predict the CTR from those metrics](C:\Users\dundeva\Documents\SPS\IS643\assign2_pic1.png)

![Tradeoff between maximum Coverage and Maximum Accuracy](C:\Users\dundeva\Documents\SPS\IS643\assign2_pic2.png)

###Discuss how you might implement some of the ideas from the talk in an existing or imagined recommender system.  

Good idea for this personalization metrics could take in to consideration a geographic metric or time related metric i.e. week end vs midweek, is there a better tradeoff between accuracy and diversity 

